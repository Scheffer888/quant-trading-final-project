{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from settings import config\n",
    "from pull_taq import get_taq_nbbo, get_taq_wct\n",
    "from transform_taq import extract_features_taq\n",
    "from strategy import (\n",
    "    create_labels,\n",
    "    train_ml_model_pipeline,\n",
    "    signal_to_returns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change default pandas display options\n",
    "\n",
    "pd.options.display.max_columns = 30\n",
    "pd.options.display.max_colwidth = 200\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "# Global variables\n",
    "RAW_DATA_DIR = Path(config(\"RAW_DATA_DIR\"))\n",
    "RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_DIR = Path(config(\"OUTPUT_DIR\"))\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_DATA_DIR = Path(config(\"PROCESSED_DATA_DIR\"))\n",
    "PROCESSED_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "WRDS_USERNAME = config(\"WRDS_USERNAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load TAQ data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Quotes Data\n",
    "\n",
    "Pull quotes data from TAQ database (NBBO)\n",
    "- Display first 5 rows to confirm data is loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = get_taq_nbbo(('SPY'), date='2024-03-07', use_bars=False)\n",
    "display(quotes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Trades Data\n",
    "\n",
    "Pull quotes data from Trades database (WCT)\n",
    "- Display first 5 rows to confirm data is loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = get_taq_wct(('SPY'), date='2024-03-07')\n",
    "display(trades.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 2. Data Preparation & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Merge Quotes and Trades\n",
    "\n",
    "Asof-join of quotes and trades dataframes\n",
    "- Match each trade with the most recent quote, keeping only rows with actual trades (left join) (that naturally discards pure-quote timestamps that lack trades.)\n",
    "- Display first 5 rows to confirm data is loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asof-join on trade_ts (left side) to quote_ts (right side).\n",
    "merged_trades = pd.merge_asof(\n",
    "    trades.sort_values(\"time_trade\"),\n",
    "    quotes.sort_values(\"time_quote\")[[\"time_quote\", \"best_bid\", \"best_bidsizeshares\", \"best_ask\", \"best_asksizeshares\"]],\n",
    "    left_on=\"time_trade\",\n",
    "    right_on=\"time_quote\",\n",
    "    direction=\"backward\"  # Ensures we take the most recent quote before the trade\n",
    ")\n",
    "merged_trades = merged_trades.drop(columns=\"time_quote\")\n",
    "display(merged_trades.head())\n",
    "\n",
    "# Save the merged trades to cache\n",
    "merged_trades.to_csv(PROCESSED_DATA_DIR / \"merged_trades.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2. Feature Engineering\n",
    "\n",
    "---\n",
    "#### **Duration since last trade**:\n",
    "- Time since the last trade.\n",
    "\n",
    "---\n",
    "#### **Mid price**:\n",
    "- Average of the best bid and ask prices.\n",
    "$$MP = \\frac{\\text{best bid price} + \\text{best ask price}}{2}$$\n",
    "\n",
    "---\n",
    "#### **EWMA Price Returns**:\n",
    "- To mitigate tick sensitivity, we can compute returns using an exponentially weighted moving average (EWMA) of past prices.\n",
    "$$\n",
    "r_t^{(T)} = \\log \\left( \\frac{P_t}{\\text{EWMA} \\left(P, \\lambda = \\frac{1}{T} \\right)} \\right)\n",
    "$$\n",
    "- This smooths out price fluctuations and provides a more stable return measure.\n",
    "\n",
    "\n",
    "---\n",
    "#### **Order-weighted average price**:\n",
    "- Weighted average of the best bid and ask prices.\n",
    "$$\n",
    "OWA = \\frac{\\sqrt{\\text{ask size}}}{\\sqrt{\\text{ask size} + \\text{bid size}}} \\times \\text{best bid price} + \\frac{\\sqrt{\\text{bid size}}}{\\sqrt{\\text{ask size} + \\text{bid size}}} \\times \\text{best ask price}\n",
    "$$\n",
    "\n",
    "---\n",
    "#### **Spread**:\n",
    "- Difference between the best ask and bid prices.\n",
    "$$\\text{Spread} = \\text{best ask price} - \\text{best bid price}$$\n",
    "\n",
    "---\n",
    "#### **Rolling Spread Mean, Coefficient of Variation & Z-score**:\n",
    "- Instead of just using the instantaneous spread, we track its mean, coefficient of variation and z-score over a given rolling time period.\n",
    "$$\n",
    "\\text{Spread Mean}_t = \\frac{1}{T} \\sum_{i=t-T}^{t} \\text{Spread}_i\n",
    "$$\n",
    "$$\n",
    "\\text{Spread CV}_t = \\frac{\\text{Spread Std}_t}{\\text{Spread Mean}_t}\n",
    "$$\n",
    "$$\n",
    "\\text{Spread Z-score}_t = \\frac{\\text{Spread}_t - \\text{Spread Mean}_t}{\\text{Spread Std}_t}\n",
    "$$\n",
    "\n",
    "$$\\frac{\\text{Spread Std}_t} = \\sqrt{\\frac{1}{T} \\sum_{i=t-T}^{t} (\\text{Spread}_i - \\text{Spread Mean}_t)^2}$$\n",
    "\n",
    "- This helps detect **spread widening** events, spread instability (CV) and liquidity shocks.\n",
    "\n",
    "---\n",
    "#### **Trade direction (sign)**:\n",
    "- we mark trades with +1 for buyer-initiated, -1 for seller-initiated.\n",
    "    - Find the best bid and offer as of the trade time\n",
    "    - Compare the trade price to them\n",
    "    - If the trade price equals the best bid, mark as seller-initiated\n",
    "    - If the trade price equals the best offer, mark as buyer-initiated\n",
    "    - Otherwise, mark according to whether trade price was below or above mid price\n",
    "\n",
    "---\n",
    "#### **Size imbalance**:\n",
    "- A common intuition among traders is that the order sizes displayed at the top of the book reflect the general intention of the market. When the number of shares at the bid exceeds that at the ask, participants  expect the next price movement to be upwards, and vice versa. \n",
    "\n",
    "$$\\text{SI} = \\frac{\\text{ask size} - \\text{bid size}}{\\text{ask size} + \\text{bid size}}$$\n",
    "\n",
    "---\n",
    "#### **Order imbalance**:\n",
    "- The order imbalance is the absolute difference between the volume of buyer-initiated and seller-initiated trades, divided by their sum over a _fixed volume bucket_.\n",
    "- This metric is designed to measure market stress, not directional bias, which is why we take the absolute valueâ€”positive and negative imbalances would cancel each other out, potentially understating the overall level of informed trading.\n",
    "\n",
    "$$\\text{I}_n = \\frac{\\left| V_n^B - V_n^S \\right|}{V_n^B + V_n^S}$$\n",
    "\n",
    "(_where $V_n^B$ and $V_n^S$ are the volume of buyer-initiated and seller-initiated trades in the _n-th fixed volume bucket_, respectively._)\n",
    "\n",
    "---\n",
    "#### **Volume-weighted probability of informed trading (VPIN)**:\n",
    "- The rolling average of Order Imbalance over the last _$N$ volume buckets_.\n",
    "\n",
    "$$VPIN = \\frac{1}{N} \\sum_{n=1}^{N} I_n$$\n",
    "\n",
    "where each $OI_n$ corresponds to the order imbalance calculated for a fixed-volume bucket, ensuring that VPIN reflects market activity in a volume-synchronized manner rather than fixed time or trade intervals.\n",
    "\n",
    "---\n",
    "#### **Trade Flow**:\n",
    "- An extension of the VPIN, a running tally of signed trade sizes where the sign is defined as 1 if the trade was seller-initiated and -1 if it was buyer-initiated.\n",
    "- At any moment, we examine all reported trades within the last time period of length $\\tau$.\n",
    "- The essential idea behind flow as a quantitative metric is that, in circumstances when many sellers are willing to cross that market-making bid-offer spread to complete their transactions, there is likely to be new information driving their choices. We do not know exactly what it is, but we certainly want to adapt to it.\n",
    "\n",
    "- When flow has a stable sign over macroscopic periods of time, it is a manifestation of supply and demand imbalance, and so it (usually) corresponds to steady price movements over a given time period.\n",
    "\n",
    "$$F_t^{(\\tau)} = V_{(t-\\tau, t)}^B - V_{(t-\\tau, t)}^S$$\n",
    "\n",
    "---\n",
    "#### **Order Flow Imbalance (OFI)**:\n",
    "- A measure of excess buying or selling pressure at the top of the order book, it represents the changes in supply and demand at the best bid and ask prices.\n",
    "$$\n",
    "\\text{OFI} = (\\text{Best Bid Size}_{t} - \\text{Best Bid Size}_{t-1}) - (\\text{Best Ask Size}_{t} - \\text{Best Ask Size}_{t-1})\n",
    "$$\n",
    "- Best bid or size at the best bid increase -> increase in demand.\n",
    "- Best bid or size at the best bid decreases -> decrease in demand.\n",
    "- Best ask decreases or size at the best ask increases -> increase in supply.\n",
    "- Best ask increases or size at the best ask decreases -> decrease in supply.\n",
    "\n",
    "---\n",
    "#### **Market Pressure (MP)**:\n",
    "- Captures the aggressiveness of market orders relative to available liquidity.\n",
    "- Higher values indicate stronger directional pressure.\n",
    "$$\n",
    "\\text{MP}_t = \\frac{\\text{Trade Volume}_t}{\\text{Bid Size}_t + \\text{Ask Size}_t}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_df = extract_features_taq(merged_trades,\n",
    "                            half_life_s=60,\n",
    "                            spread_window=\"60s\",\n",
    "                            flow_time_step=\"100ms\",\n",
    "                            flow_window=\"5s\",\n",
    "                            bucket_size=1000,\n",
    "                            vpin_buckets=30,\n",
    "                            vwap_past_window=\"60s\",\n",
    "                            vwap_future_window=\"20s\")\n",
    "print(feats_df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feats_df.isnull().sum())  # Count NaNs in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_df = feats_df.dropna()\n",
    "\n",
    "# Create prices df for strategy simulation\n",
    "best_price_df = feats_df.set_index('time_trade')[['best_bid', 'best_ask']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 3. Machine Learning Model for Trade Signal Prediction\n",
    "\n",
    "**Overview**\n",
    "\n",
    "This section outlines the end-to-end pipeline for building a machine learning model to predict trade signals based on market microstructure features. The objective is to classify each time step into one of three categories:  \n",
    "- **Buy signal (+1)** â†’ Indicates a likely upward price movement.  \n",
    "- **Hold signal (0)** â†’ No action recommended.  \n",
    "- **Sell signal (-1)** â†’ Indicates a likely downward price movement.  \n",
    "\n",
    "We achieve this through feature engineering, time-series cross-validation, model training, and performance evaluation.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3.1. Future Return Calculation & Signal Labeling\n",
    "To train a classification model, we first compute the **future return** based on the future VWAP and the current price. This helps us create a label for supervised learning.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. _Compute the log future return:_\n",
    "   \\[\n",
    "   \\text{future\\_return}_t = \\log\\left(\\frac{\\text{future\\_VWAP}_t}{\\text{price}_t}\\right)\n",
    "   \\]\n",
    "2. _Classify each time step into buy/hold/sell:_\n",
    "   - A **buy signal (+1)** is assigned if the future return exceeds **mean + std deviation**.\n",
    "   - A **sell signal (-1)** is assigned if the future return is below **mean - std deviation**.\n",
    "   - Otherwise, a **hold signal (0)** is assigned.\n",
    "\n",
    "    _Note: there is some look-ahead bias in this approach, since we are using all data to calculate the mean and standard deviation, but we will acception that for this exercise_.\n",
    "\n",
    "3. _Remove any missing values** to ensure consistency in modeling._\n",
    "\n",
    "---\n",
    "\n",
    "#### 3.2. Machine Learning Model Training\n",
    "We use a **Random Forest Classifier** with hyperparameter tuning to predict future price movements.\n",
    "\n",
    "**Preprocessing & Feature Scaling**\n",
    "- _Feature Scaling_: Certain features (e.g., `trade_sign`, `spread_Zscore`) do not require scaling, while others benefit from StandardScaler.\n",
    "- _Dimensionality Reduction (Optional):_ If needed, _PCA_ is applied to reduce redundant information.\n",
    "\n",
    "**Time-Series Cross-Validation**\n",
    "Unlike traditional cross-validation, time-series data requires __forward-looking validation_:\n",
    "- We use _TimeSeriesSplit_ to progressively expand the training set.\n",
    "- The test set always consists of future unseen data.\n",
    "\n",
    "**Hyperparameter Optimization**\n",
    "- We use _RandomizedSearchCV_ to find the best hyperparameters for:\n",
    "  - `max_depth`\n",
    "  - `min_samples_split`\n",
    "  - `n_estimators`\n",
    "- The best model is selected based on _**_cross-validation accuracy_.\n",
    "\n",
    "**Model Evaluation**\n",
    "- Performance is measured using _Accuracy_ and _F1-score_ on both training and test sets.\n",
    "- A final holdout test set ensures realistic performance assessment.\n",
    "- The trained model is saved for future predictions.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.3. Trade Execution & Strategy Return Calculation\n",
    "Once the model generates trade signals, we must determine the **actual execution price** and compute **strategy returns**.\n",
    "\n",
    "**Trade Execution Rules**\n",
    "- If _signal = +1_, we _buy_ at the next _best ask price_ (after a 1ms delay).\n",
    "- If _signal = -1_, we _sell_ at the next _best bid price_.\n",
    "- If _signal changes from +1 to -1**, a _full reversal_ occurs, meaning we sell the current position and take a new short position.\n",
    "- If _signal changes from -1 to +1_, we close the short position and enter a long.\n",
    "\n",
    "**Trade Size Scaling**\n",
    "Each trade is adjusted based on _up_weight_ and _down_weight_:\n",
    "- `up_weight` scales the size of long trades.\n",
    "- `down_weight` scales the size of short trades.\n",
    "- If moving from neutral to long, the trade size is `+up_weight`.\n",
    "- If moving from neutral to short, the trade size is `-down_weight`.\n",
    "- If flipping long to short, the total trade size is `-(up_weight + down_weight)`.\n",
    "- If flipping short to long, the total trade size is `+(up_weight + down_weight)`.\n",
    "\n",
    "**Strategy Return Calculation**\n",
    "- The trade price is determined at execution (`ask` for buys, `bid` for sells).\n",
    "- We consider a total transaction cost of 0.01% of price for each trade.\n",
    "- The _strategy return_ is computed as:\n",
    "  $$\n",
    "  \\text{strategy\\_return}_t = \\text{trade\\_size}_{t-1} \\times \\frac{\\text{executed\\_price}_t}{\\text{executed\\_price}_{t-1}} - 1\n",
    "  $$\n",
    "- Returns are _cumulative_ over time, forming the basis of strategy performance evaluation.\n",
    "\n",
    "\n",
    "This methodology provides a scalable approach for predicting market movements and evaluating systematic trading strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create future return & classification labels\n",
    "LABEL_COL=\"ml_signal\"\n",
    "\n",
    "feats_df = create_labels(\n",
    "    feats_df,\n",
    "    price_col=\"price\",\n",
    "    future_vwap_col=\"future_vwap\",\n",
    "    out_return_col=\"future_return\",\n",
    "    out_label_col=LABEL_COL,\n",
    "    buy_threshold_std=1.0,\n",
    "    sell_threshold_std=1.0,\n",
    ")\n",
    "\n",
    "# Select relevant features\n",
    "feats_df = feats_df[[\n",
    "        \"ewma_mid_price_return\",\n",
    "        \"trade_sign\",\n",
    "        \"duration_since_last_trade\",\n",
    "        \"size_imbalance\",\n",
    "        \"market_pressure\",\n",
    "        \"OFI\",\n",
    "        \"trade_flow\",\n",
    "        \"spread_mean\",\n",
    "        \"spread_CV\",\n",
    "        \"spread_Zscore\"\n",
    "    ]]\n",
    "\n",
    "print(feats_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- There are only 4 missing values, so we will remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if model already exists:\n",
    "MODEL_NAME = \"random_forest_hft_signal\"\n",
    "model_path = f\"{OUTPUT_DIR}/models/{MODEL_NAME}.pkl\"\n",
    "if Path(model_path).exists():\n",
    "    print(f\"Model already exists at {model_path}\")\n",
    "    ml_model = joblib.load(model_path)\n",
    "\n",
    "else:    \n",
    "    # Train the ML pipeline\n",
    "    ml_model = train_ml_model_pipeline(\n",
    "        data=feats_df,\n",
    "        label_col=LABEL_COL,\n",
    "        use_pca=True,\n",
    "        pca_components = 0.90,\n",
    "        train_size=0.8,\n",
    "        model_name=\"random_forest_hft_signal\",\n",
    "        model_path = f\"{OUTPUT_DIR}/models/\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate signals from the model:\n",
    "features_only = feats_df.drop(columns=[LABEL_COL], errors=\"ignore\")\n",
    "signals = ml_model.predict(feats_df.dropna())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert signals to actual strategy returns using next ask price:\n",
    "signals_df = pd.DataFrame(signals, index=best_price_df.index, columns=[\"signals\"])\n",
    "STRATEGY_NAME = \"ML_strategy\"\n",
    "strategy_ret = signal_to_returns(\n",
    "    signals=signals_df, \n",
    "    best_prices=best_price_df, \n",
    "    strategy_name=STRATEGY_NAME, \n",
    "    lookahead_timedelta=pd.Timedelta(\"1ms\")\n",
    ")\n",
    "\n",
    "# Evaluate strategy performance\n",
    "cum_ret = (1.0 + strategy_ret[f\"{STRATEGY_NAME}_returns\"]).cumprod() - 1.0\n",
    "print(\"Final strategy return = \", cum_ret.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
